# Multimodal-Activity-Classification
6.S191 Deep Learning Project: Classifying Activities from information of various source types. 


### 1. Initial Data is Collected or Scrapped From Yelp, BBC, or Google Search </br>
Snapshot of Reviews Collected From Yelp </br>
<p align="center">
  <img src="https://user-images.githubusercontent.com/85134229/151624020-8271d0a2-207d-43c2-a3f3-c3ee161646cc.png" | width=500/> </br>
</p>
</br>
</br>
Snapshot of Website Information Collected from Google </br>
<p align="center">
  <img src="https://user-images.githubusercontent.com/85134229/152094927-c22f7ffe-5143-4b88-a00c-231bccbb2a7e.png" | width=500/> </br>
</p>
</br>
</br>
</br>
### 2. Text Processing Tokenized Text </br>
Specifically, I removed all stop words, numbers, punctuation, and non-english words (not taking into account mis-spelling). I then tokenized by words and stored them in an array. </br>
<p align="center">
  <img src="https://user-images.githubusercontent.com/85134229/152095648-7fff8260-a334-45e9-a216-df888a4443c9.png" | width=700/> </br>
</p>
