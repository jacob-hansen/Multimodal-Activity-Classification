{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YelpScrapper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6+V8ODK6nN2EBEY3IXKvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacob-hansen/Multimodal-Activity-Classification/blob/main/YelpScrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "00YC6mRwTjxr"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from csv import writer\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "metadata": {
        "id": "wfVb4ZZ-kKp3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "worksheet = gc.open('A new spreadsheet').sheet1\n",
        "sh = gc.create('Yelp Scraping Data')"
      ],
      "metadata": {
        "id": "LpLCEwphogSs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "citiesList = [[\"MA\", \"Somerville\"]]#, [\"MA\", \"Cambridge\"]]\n",
        "maxListings = 100 # takes approximatly the top 10*(maxListings//10) listings\n",
        "maxReviewNum = 100 # takes approximatly the top 10*(maxReviewNum//10) reviews\n",
        "tempReview = []  # temporarily stores review data\n",
        "headerrow = [\"Place Number\", \"Place Name\", \"Review Rating\", \"Text\", \"Place URL\"]"
      ],
      "metadata": {
        "id": "kSUFj2tVTlqY"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "worksheet = gc.open('Yelp Scraping Data').sheet1\n",
        "worksheet.update('A'+str(1)+':E'+str(1), [headerrow])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz3tExEXkTD3",
        "outputId": "f399ab66-5cfb-4f9b-f484-fe8f7291bda5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1-LeBNycotuCkFlnbCcxLWU9NOqNtn_XStoyaFIANSY0',\n",
              " 'updatedCells': 5,\n",
              " 'updatedColumns': 5,\n",
              " 'updatedRange': 'Sheet1!A1:E1',\n",
              " 'updatedRows': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cityPlaces = []\n",
        "for row in citiesList:\n",
        "    currentState = row[0]\n",
        "    for currentCity in row[1:]:\n",
        "        searchURL = (\n",
        "            \"https://www.yelp.com/search?find_desc=activities&find_loc=\"\n",
        "            + currentCity\n",
        "            + \"%2C+\"\n",
        "            + currentState\n",
        "            + \"&ns=1&sortby=review_count&start=\"\n",
        "        )\n",
        "        placeList = []\n",
        "        i = 0\n",
        "        while i < maxListings:\n",
        "            \"\"\"Pull All the objects of the right class from each page\"\"\"\n",
        "            restaurantSearchPage = requests.get(searchURL+str(i))\n",
        "            restaurantSearchPageSoup = BeautifulSoup(\n",
        "                restaurantSearchPage.text, \"html.parser\")\n",
        "            newData = restaurantSearchPageSoup.findAll(class_=\"css-1uq0cfn\")\n",
        "            \"\"\"Pull URL extentions for objects of interest\"\"\"\n",
        "            noValidData = True\n",
        "            for data in newData:\n",
        "                try:\n",
        "                    if not data.find(\"a\")[\"href\"]:\n",
        "                        continue\n",
        "                    else:\n",
        "                        placeURLEnding = data.find(\"a\")[\"href\"]\n",
        "                        placeList.append(placeURLEnding)\n",
        "                        noValidData = False\n",
        "                except TypeError:\n",
        "                    continue\n",
        "            if noValidData: # Page has no more listings\n",
        "                break\n",
        "            else: # Up the count and keep searching\n",
        "                i += 10\n",
        "            sleep(random.uniform(0, 2)) # Wait random time 0-2 seconds to not get blocked\n",
        "\n",
        "        cityPlaces.append(placeList)\n",
        "\n",
        "  \n",
        "        # gets URL for each restaurant listing\n",
        "        "
      ],
      "metadata": {
        "id": "muVbk70LTxr0"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "worksheet = gc.open('Yelp Scraping Data').sheet1\n",
        "activityInc = 0\n",
        "worksheetRow = 1001\n",
        "for city in cityPlaces:\n",
        "  for urlExt in city[11:]:\n",
        "      print(\"Scraping \"+\"https://yelp.com\"+urlExt)\n",
        "      placeURL = \"https://yelp.com\" + urlExt\n",
        "      placeName = ((urlExt.split(\"/\")[-1]).split(\"?\"))[0].replace(\"-\", \" \")\n",
        "      i = 0\n",
        "      while i < maxReviewNum:\n",
        "          try:\n",
        "              placeURL = \"https://yelp.com/\" + urlExt + \"&start=\" + str(i)\n",
        "              placePage = requests.get(placeURL)\n",
        "              placePageSoup = BeautifulSoup(\n",
        "                  placePage.text, \"html.parser\")\n",
        "              i += 10\n",
        "              reviewsRawList = placePageSoup.findAll(\"div\", class_=\" review__09f24__oHr9V border-color--default__09f24__NPAKY\",)\n",
        "              print(len(reviewsRawList))\n",
        "              for review in reviewsRawList:\n",
        "                  reviewRating = int(review.find(class_=\"i-stars__09f24__foihJ\").get(\"aria-label\")[0])\n",
        "                  reviewText = review.find(class_ = \"raw__09f24__T4Ezm\").get_text()\n",
        "                  tempReview = []\n",
        "                  tempReview.append(activityInc)\n",
        "                  tempReview.append(placeName)\n",
        "                  tempReview.append(reviewRating)\n",
        "                  tempReview.append(reviewText)\n",
        "                  tempReview.append(placeURL)\n",
        "                  worksheet.update('A'+str(worksheetRow)+':E'+str(worksheetRow), [tempReview])\n",
        "                  worksheetRow+=1\n",
        "              sleep(random.uniform(0, 5))  # Wait random time 0-2 seconds to not get blocked\n",
        "          except:\n",
        "              sleep(60)\n",
        "              continue\n",
        "      activityInc += 1"
      ],
      "metadata": {
        "id": "X_3k3DWXUANW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HjA7HB0FB5h_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}